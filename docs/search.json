[
  {
    "objectID": "market.html",
    "href": "market.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "This page is for internal use only. If you are not a letter writer, I encourage you to use the navigation tab to learn more about me and my work."
  },
  {
    "objectID": "market.html#welcome",
    "href": "market.html#welcome",
    "title": "Job Market Hub",
    "section": "",
    "text": "This page is for internal use only. If you are not a letter writer, I encourage you to use the navigation tab to learn more about me and my work."
  },
  {
    "objectID": "market.html#upcoming-deadlines",
    "href": "market.html#upcoming-deadlines",
    "title": "Job Market Hub",
    "section": "Upcoming Deadlines",
    "text": "Upcoming Deadlines\nLast update: August 23, 2024. Full list here.\nNumber of letters to write:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nNA - NA - NALetters:  Deadline: NA  Delivery: NA  Notes: NA  \n \n** - - **Letters:  Deadline:  Delivery:  Notes:"
  },
  {
    "objectID": "market.html#materials",
    "href": "market.html#materials",
    "title": "Job Market Hub",
    "section": "Materials",
    "text": "Materials\nMethods is the default set of materials\n\nCover letter [Methods] [Comparative] [Statistics]\nResearch statement [Methods] [Comparative] [Statistics]\nTeaching statement [Methods] [Comparative] [Statistics]\nDiversity statement [Methods] [Comparative] [Statistics]"
  },
  {
    "objectID": "market.html#research",
    "href": "market.html#research",
    "title": "Job Market Hub",
    "section": "Research",
    "text": "Research\nHighlights here. See the research tab for more.\n\nMethods\n\nAssessing the Validity of Prevalence Estimates in Double List Experiments\nJournal of Experimental Political Science\nPaper Appendix\n\nReview process complete, official version should come soon\nI started working on this before working on my dissertation!\n\nBalancing Precision and Retention in Experimental Design\nwith Erin Rossiter\nPaper Appendix\n\nUnder review in APSR\n\nList experiment and Network Scale-up questions to measure criminal governance strategies in Uruguay\nwith Ines Fynn, Verónica Pérez Bentancur, and Lucía Tiscornia\n\nOngoing project that should yield 4 papers:\n\n\nCombining list experiments and network scale-up questions to improve measurement of sensitive attitudes (Presenting at Polmeth, Maplemeth, Toronto Behavior Workshop, maybe LAPolmeth)\nRecovering estimates when placebo statements mess up your list experiment\nShort piece documenting extent of criminal governance activity in a context of low crime and high state presence (Presenting at APSA)\nLonger piece same as (3) but delving deeper into theory and field interviews\n\nSurvey Experiments and the Quest for Valid Interpretation\nwith Christopher Grady and James H. Kuklinski\nIn: Luigi Curini and Robert Franzese (eds)\nThe SAGE Handbook of Research Methods in Political Science and International Relations, 2020\nChapter Handbook\n\n\n\nComparative\n\nIgnoring Female Performance: A Survey Experiment on Policy Implementation in Argentina\nwith Virginia Oliveros, Rebecca Weitz-Shapiro, and Matthew S. Winters\nPaper Appendix\n\nUnder review at BJPS\n\nMayors Alter Spending to Counter the Electoral Consequences of Increased Monitoring: Evidence from Anti-Corruption Audits in Brazil\nPaper\n\nPresenting at APSA. Presented in political economy of development workshop organized by the Journal of Public Policy\n\nRevealing Nearby Corruption Drives Party Switching: Evidence from Local Level Audits in Brazil\nPaper\n\nOld job talk\n\nLight in the Midst of Chaos: COVID-19 and Female Political Representation\nwith Kelly Senters Piazza\nWorld Development 136: 105125, 2020\nPaper"
  },
  {
    "objectID": "market.html#teaching",
    "href": "market.html#teaching",
    "title": "Job Market Hub",
    "section": "Teaching",
    "text": "Teaching\n\nMcMaster course website: popw23.gustavodiaz.org\nSyllabi\nTeaching evaluations"
  },
  {
    "objectID": "market.html#other-stuff",
    "href": "market.html#other-stuff",
    "title": "Job Market Hub",
    "section": "Other stuff",
    "text": "Other stuff\nSection in progress. Things that may be missing or understated in current materials.\n\nWorking on text analysis modeling to analyze citation patterns in methodology across social sciences as part of postdoc duties\nAttending a grant writing workshop in the Fall, focus on preparing an application for an NSF-equivalent grant in Canada\nDissertation data collection combines text analysis and supervised learning to create most up to date data set of Brazilian local anti-corruption audits\nDissertation got poster award at Latin American Polmeth 2019\nCool places I have interviewed but not taken jobs at that may make people feel like they need to hire me before someone else does:\n\n\nPenn State, University of Konstanz, University of Birmingham, Howard University, William & Mary, KDI School of Public Policy and Management, Carlos III-Juan March Institute of Social Sciences, University of Melbourne\n\n\nWent to EITM at Emory in 2019\nHave experience mentoring an undergrad RA. Used it as an excuse so we could both learn text analysis. Student got job as data consultant after college. I claim all the credit\nLast 3 years have been marked by: Pandemic, parenting, moving, escaping from hurricane, immigration troubles, family illness. This is the first summer since 2020 without a major life thing going on. Feel free to weave that in your assessment of my productivity if you feel it may help"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Last update: August 22, 2025. Full list here.\nNumber of letters to write:\n\n\n\n\n\nJake\nMatt\nMichelle\n\n\n\n\n3\n2\n2\n\n\n\n\n\n \nAssistant Professor in Comparative Politics/International Relations - Department of Political Science - Sogang UniversityLetters: Jake  Deadline: August 27, 2025  Delivery: After shortlist?  Notes: Been in contact with Shang E. Ha and Silvia Kim about this position  \n \nAssistant Professor - Department of Political Science - Texas A&M UniversityLetters: Jake, Matt, Michelle  Deadline: September 1, 2025  Delivery: Interfolio  Notes: Contact information for two additional references. I heard down the grapevine that they recently lost two methodologists  \n \nAssistant Professor in research methods and political psychology - Department of Political Science and International Relations - Loyola Marymount UniversityLetters: Jake, Matt, Michelle  Deadline: September 8, 2025  Delivery: Email Luke Hart-Moynihan at luke.hart-moynihan@lmu.edu  Notes: The successful candidate is expected to contribute at least two courses per year to the new Applied Data Analysis minor (i.e. the introductory undergraduate quantitative research methods course and another methods course)."
  },
  {
    "objectID": "index.html#upcoming-deadlines",
    "href": "index.html#upcoming-deadlines",
    "title": "Job Market Hub",
    "section": "",
    "text": "Last update: August 22, 2025. Full list here.\nNumber of letters to write:\n\n\n\n\n\nJake\nMatt\nMichelle\n\n\n\n\n3\n2\n2\n\n\n\n\n\n \nAssistant Professor in Comparative Politics/International Relations - Department of Political Science - Sogang UniversityLetters: Jake  Deadline: August 27, 2025  Delivery: After shortlist?  Notes: Been in contact with Shang E. Ha and Silvia Kim about this position  \n \nAssistant Professor - Department of Political Science - Texas A&M UniversityLetters: Jake, Matt, Michelle  Deadline: September 1, 2025  Delivery: Interfolio  Notes: Contact information for two additional references. I heard down the grapevine that they recently lost two methodologists  \n \nAssistant Professor in research methods and political psychology - Department of Political Science and International Relations - Loyola Marymount UniversityLetters: Jake, Matt, Michelle  Deadline: September 8, 2025  Delivery: Email Luke Hart-Moynihan at luke.hart-moynihan@lmu.edu  Notes: The successful candidate is expected to contribute at least two courses per year to the new Applied Data Analysis minor (i.e. the introductory undergraduate quantitative research methods course and another methods course)."
  },
  {
    "objectID": "index.html#materials",
    "href": "index.html#materials",
    "title": "Job Market Hub",
    "section": "Materials",
    "text": "Materials\n\nCV\nCover letter\nResearch statement\nTeaching statement\nDiversity statement"
  },
  {
    "objectID": "index.html#papers",
    "href": "index.html#papers",
    "title": "Job Market Hub",
    "section": "Papers",
    "text": "Papers\nTBD. See research and talks pages for now."
  },
  {
    "objectID": "index.html#teaching-portfolio",
    "href": "index.html#teaching-portfolio",
    "title": "Job Market Hub",
    "section": "Teaching portfolio",
    "text": "Teaching portfolio\nTBD. See teaching page for now."
  },
  {
    "objectID": "index.html#highlights",
    "href": "index.html#highlights",
    "title": "Job Market Hub",
    "section": "Highlights",
    "text": "Highlights"
  },
  {
    "objectID": "evals.html",
    "href": "evals.html",
    "title": "McMaster University",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\n\n \nThe following tables present a summary of my teaching evaluations. Unless otherwise noted, scores range from 1 to 5, with 5 being the most positive. Detailed evaluations available upon request."
  },
  {
    "objectID": "evals.html#teaching-evaluations",
    "href": "evals.html#teaching-evaluations",
    "title": "McMaster University",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\n\n \nThe following tables present a summary of my teaching evaluations. Unless otherwise noted, scores range from 1 to 5, with 5 being the most positive. Detailed evaluations available upon request."
  },
  {
    "objectID": "evals.html#selected-comments-from-students-at-tulane",
    "href": "evals.html#selected-comments-from-students-at-tulane",
    "title": "McMaster University",
    "section": "Selected comments from students at Tulane",
    "text": "Selected comments from students at Tulane\n\n“Professor Diaz is very understanding and does a great job applying concepts to class discussions and the out-of-class assignments reflect the key concepts of the course.”\n“I appreciated the flexible exam structure and edits made to the syllabus as a result of the challenges of this semester. I enjoyed the News Report assignments as they were an interesting way to interact with the course content in a meaningful way.”\n“The organization of content felt extremely coherent as we built on every previous module. This is no small feat given the subject matter. The mixture of quizzes and News Report assignments kept the course from being stale while still testing our knowledge of course material from differing vectors.”"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\n\n\nAs someone teaching introductory courses in quantitative methods to political scientists, I face a polarized audience. Some students start their program with considerable experience on mathematical thinking, statistics, and statistical programming. Others start with an appreciation for quantitative research, but come from career paths designed to explicitly avoid math.\nMy approach to keep both audiences engaged within one term is to unify math, statistics, and coding as the task of acquiring a new language. A single course will not teach students everything they need to know to become fluent, but it can give enough tools to facilitate future learning in a direction that is beneficial to students with diverse backgrounds and career goals. For some, this may mean engaging directly with data and code or even creating new methodologies. For others, the goal may be just to communicate productively with scholarship drawing on quantitative findings or data analysts at the workplace.\nTo accommodate this diversity, I design courses with two principles in mind. First, students need flexibility to engage with the course on their own terms and focus on the content they find useful. For example, the flipped classroom lab sessions in my course on data analysis for public opinion and policy at McMaster asked students to evaluate a research design, suggest alternatives or modifications, and to evaluate its statistical properties through coding and writing. Some students may propose increasing the sample size, sampling from a different underlying population, or changing the assignment of treatment conditions. This allows students to pursue the tasks that suit their interests and gives me the freedom to reward creativity and effort over correctness. This principle also applies to the problem sets in my graduate introductory methods course, where contract grading allows me to reward learning even when student stuck on coding errors.\nThe second principle is accountability, which is necessary to keep everyone on task while allowing flexibility. This means agreeing on an overarching theme that every single course activity must relate to. For example, early on my data analysis for public opinion and policy course, I introduce the bias-variance tradeoff as a principle to choose among alternative research designs. So, while students are free to propose any modification to an existing research design that they deem appropriate, they are also required to document the explicit or implicit costs that would come from their proposal. They must consider, for instance, that a representative sample is more expensive than a convenience sample, or that implementing a block-randomized experiment may require access to variables that cannot be measured easily. I plan to apply the same principle in my upcoming seminar on methods for evidence-informed decision-making.\nFlexibility and accountability also help in preventing instances of discrimination in the learning process. Through flexibility, students are invited to add value to the course by bringing their own perspective, knowledge, or experiences. In turn, accountability sets the scope for the type of contributions of interventions that are admissible. From this perspective, a racist remark is unacceptable not because someone disagrees with it, but because it is beyond the scope of the course vocabulary.\n\n\nAt Northwestern, I am the central person teaching quantitative methods in the department. I teach the first course in the graduate methods sequence, focusing on probability and statistical inference. I also lead the math camp for incoming political science and sociology students and run the year-long R workshop that introduces cutting-edge statistical programming practices. Later this year, I will teach the undergrad level introduction to research methods in political science, and a seminar on causal inference and machine learning methods for evidence-based policy-making.\nBefore joining Northwestern, I taught data analysis for public policy and public opinion at McMaster, with emphasis on experimental and quasi-experimental designs for causal inference. The goal of this course is to give students hands-on experience in designing quantitative research projects in an area relevant to academia, policy, or industry.\nAt Tulane, I taught an undergrad senior course on the challenges of developing democracies from the perspective of evidence-based policy making. This course overviews the main challenges in the path to democratic consolidation around the world, the proposed solutions to these challenges, and how governments, researchers, and civil society organizations use data to evaluate these solutions. The previous version focused primarily design-based causal inference, but future versions will also feature big data and machine learning.\nIn my time as a PhD student at Illinois, I taught statistics and research methods. In the 2020-2021 academic year, I was the graduate methods teaching assistant in our department. My duties involved advising PhD students taking courses in the quantitative methods sequence, as well as mentoring undergraduates enrolled in the senior honors thesis program. I also served as a teaching assistant for Jake Bowers’ introduction to data analysis for political science majors. This course focuses on flipped classroom learning, letting students engage with the course material on their own time and using lecture time to work as a group on problem sets and research projects. I have also contributed as a math camp instructor for three consecutive years, introducing statistical programming in R to incoming graduate students in our department. I also had experience teaching substantive courses using online and hybrid formats.\nTeaching to these diverse audiences made me aware of the importance of promoting out-of classroom learning experiences. I organized a reading group on computational social science at Illinois that met regularly in the Summer and Fall of 2017. I started a a collaborative project in which graduate students share cheatsheets introducing their fellows to new methodological tools. I have also enjoyed the experience of mentoring an undergraduate research assistant, using the opportunity to help both of us learn text analysis. In the future, I plan to facilitate and institutionalize similar learning experiences in every aspect of my work.\n\n\n\nI am prepared to teach courses on statistics, research design, experiments, causal inference, machine learning, and computational social science. You can find copies of current and future syllabi in my website."
  },
  {
    "objectID": "teaching.html#teaching-statement",
    "href": "teaching.html#teaching-statement",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\n\n\nAs someone teaching introductory courses in quantitative methods to political scientists, I face a polarized audience. Some students start their program with considerable experience on mathematical thinking, statistics, and statistical programming. Others start with an appreciation for quantitative research, but come from career paths designed to explicitly avoid math.\nMy approach to keep both audiences engaged within one term is to unify math, statistics, and coding as the task of acquiring a new language. A single course will not teach students everything they need to know to become fluent, but it can give enough tools to facilitate future learning in a direction that is beneficial to students with diverse backgrounds and career goals. For some, this may mean engaging directly with data and code or even creating new methodologies. For others, the goal may be just to communicate productively with scholarship drawing on quantitative findings or data analysts at the workplace.\nTo accommodate this diversity, I design courses with two principles in mind. First, students need flexibility to engage with the course on their own terms and focus on the content they find useful. For example, the flipped classroom lab sessions in my course on data analysis for public opinion and policy at McMaster asked students to evaluate a research design, suggest alternatives or modifications, and to evaluate its statistical properties through coding and writing. Some students may propose increasing the sample size, sampling from a different underlying population, or changing the assignment of treatment conditions. This allows students to pursue the tasks that suit their interests and gives me the freedom to reward creativity and effort over correctness. This principle also applies to the problem sets in my graduate introductory methods course, where contract grading allows me to reward learning even when student stuck on coding errors.\nThe second principle is accountability, which is necessary to keep everyone on task while allowing flexibility. This means agreeing on an overarching theme that every single course activity must relate to. For example, early on my data analysis for public opinion and policy course, I introduce the bias-variance tradeoff as a principle to choose among alternative research designs. So, while students are free to propose any modification to an existing research design that they deem appropriate, they are also required to document the explicit or implicit costs that would come from their proposal. They must consider, for instance, that a representative sample is more expensive than a convenience sample, or that implementing a block-randomized experiment may require access to variables that cannot be measured easily. I plan to apply the same principle in my upcoming seminar on methods for evidence-informed decision-making.\nFlexibility and accountability also help in preventing instances of discrimination in the learning process. Through flexibility, students are invited to add value to the course by bringing their own perspective, knowledge, or experiences. In turn, accountability sets the scope for the type of contributions of interventions that are admissible. From this perspective, a racist remark is unacceptable not because someone disagrees with it, but because it is beyond the scope of the course vocabulary.\n\n\nAt Northwestern, I am the central person teaching quantitative methods in the department. I teach the first course in the graduate methods sequence, focusing on probability and statistical inference. I also lead the math camp for incoming political science and sociology students and run the year-long R workshop that introduces cutting-edge statistical programming practices. Later this year, I will teach the undergrad level introduction to research methods in political science, and a seminar on causal inference and machine learning methods for evidence-based policy-making.\nBefore joining Northwestern, I taught data analysis for public policy and public opinion at McMaster, with emphasis on experimental and quasi-experimental designs for causal inference. The goal of this course is to give students hands-on experience in designing quantitative research projects in an area relevant to academia, policy, or industry.\nAt Tulane, I taught an undergrad senior course on the challenges of developing democracies from the perspective of evidence-based policy making. This course overviews the main challenges in the path to democratic consolidation around the world, the proposed solutions to these challenges, and how governments, researchers, and civil society organizations use data to evaluate these solutions. The previous version focused primarily design-based causal inference, but future versions will also feature big data and machine learning.\nIn my time as a PhD student at Illinois, I taught statistics and research methods. In the 2020-2021 academic year, I was the graduate methods teaching assistant in our department. My duties involved advising PhD students taking courses in the quantitative methods sequence, as well as mentoring undergraduates enrolled in the senior honors thesis program. I also served as a teaching assistant for Jake Bowers’ introduction to data analysis for political science majors. This course focuses on flipped classroom learning, letting students engage with the course material on their own time and using lecture time to work as a group on problem sets and research projects. I have also contributed as a math camp instructor for three consecutive years, introducing statistical programming in R to incoming graduate students in our department. I also had experience teaching substantive courses using online and hybrid formats.\nTeaching to these diverse audiences made me aware of the importance of promoting out-of classroom learning experiences. I organized a reading group on computational social science at Illinois that met regularly in the Summer and Fall of 2017. I started a a collaborative project in which graduate students share cheatsheets introducing their fellows to new methodological tools. I have also enjoyed the experience of mentoring an undergraduate research assistant, using the opportunity to help both of us learn text analysis. In the future, I plan to facilitate and institutionalize similar learning experiences in every aspect of my work.\n\n\n\nI am prepared to teach courses on statistics, research design, experiments, causal inference, machine learning, and computational social science. You can find copies of current and future syllabi in my website."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\nPolitical scientists often study phenomena that cannot be observed directly. For example, we use responses to hypothetical survey questions to infer actual behavior, we resort to aggregate election results to understand individual evaluations of politicians’ performance in office, and we conduct randomized controlled trials in some places to determine if a policy is advisable in other places. Doing this credibly requires careful research design, since researchers must try to anticipate the challenges to inference even before conducting data analysis.\nMy research develops standards to navigate the tradeoffs that emerge when one considers research design options before data collection. I use tools from causal inference and computational social science to identify practices and procedures that researchers can adopt to improve how they approach data collection at the pre-analysis stage. My current agenda focuses on improving statistical precision, since this is often the deciding factor when choosing among alternative research designs, all promising unbiased estimators.\nI apply the insights of my methodological work to questions in comparative politics and political behavior, especially around the challenges to accountability, governance, and representation. The common theme across these applications is the goal of improving our ability to make statistical inferences about hard-to-observe social and political phenomena.\n\n\n\nThe last decade has seen considerable improvement in research transparency and registration. Recent advances in experimental design provide tools to diagnose the properties of a research design before data collection. For example, one can think about bias, power, or target sample size under different hypothetical data generation processes.\nA recurrent goal in statistics, econometrics, and political methodology is to minimize bias, or being close to the hypothetical truth on average. When planning an original data collection effort, researchers can often choose among many alternative research designs, all with previously identified unbiased estimators. My agenda focuses on optimizing statistical precision, understood as producing consistent results after multiple realizations of the same data generation process. While this is a crucial factor when choosing a research design, the literature implicitly assumes that one cam simply improve precision by increasing sample size, without providing much guidance to assess among alternative designs. Moreover, simply increasing sample size is not feasible in most applications due to practical or ethical considerations. Therefore, even when one does not face a choice between alternative designs, statistical precision is still paramount.\nFocusing on the design and analysis of experiments, my agenda advances the argument that the choice between alternative research designs for which unbiased estimators are already documented is rarely free. A design promising improvements in statistical precision without sacrificing unbiasedness often brings unforeseen costs in other dimensions.\nTwo projects exemplify how I develop standards to navigate research design choice under unforeseen challenges. First, In a manuscript with Erin Rossiter (Notre Dame), we discuss the circumstances under which adopting research design features aimed at improving precision can instead hurt it through implicit or explicit sample loss. For example, block randomization can improve precision, but if this requires contacting participants multiple times to collect pre-treatment blocking covariates, then it creates space for attrition that would not exist otherwise, which may offset the precision gains from blocking. We posit this is the main reason why researchers deviate from the standard experimental design infrequently. Through three replications and six reanalyses of previously published experiments in leading political science journals, we show how precision gains from alternative designs can withstand significant degrees of sample loss. From this exercise, we also identify guidelines to navigate the tradeoff between precision and sample retention in experiments.\nSecond, in a manuscript published at the Journal of Experimental Political Science, I propose statistical tests to address problems with double list experiments. Social scientists use list experiments in surveys when respondents may not answer truthfully to sensitive questions. When their assumptions are met, list experiments reduce sensitivity biases from misreporting. However, they tend to produce estimates with high variance, which prevents researchers from improving upon direct questioning. Double list experiments promise to remedy this by implementing two parallel list experiments and then aggregating their results, which roughly halves the variance of the estimate for the prevalence of the sensitive trait.\nThis implies an estimator that is more precise and still unbiased, but their implementation brings the question over whether the aggregation of the results of two parallel experiments yields a valid estimate. The tests leverage variation in the order in which respondents see the sensitive item to detect whether respondents are reacting to list experiment questions in unintended ways. This provides researchers with a tool to apply this underexplored variant of the technique more widely.\nThis agenda is currently extending toward improving precision by combining different techniques that target the same quantity of interest. For example, in work in progress with Inés Fynn (Universidad Católica del Uruguay), Verónica Pérez (Universidad de la República), and Lucía Tiscornia (University College Dublin), we combine list experiments and the network scale up method (NSUM), a popular technique in the health sciences, to improve precision in the estimation of the prevalence of sensitive attitudes and behaviors. Previous work combining different techniques to minimize sensitivity bias in survey questions relies on asking direct questions, altered research designs, cumbersome statistical modeling assumptions, or access to population-level data, all of which are problematic in their own way. By using NSUM questions as auxiliary information to the list experiment, we manage to improve precision by only imposing one additional assumption: that people with disproportionally high exposure to the sensitive trait of interest in their personal network are likely to hold the trait themselves. This does not apply to every sensitive attitude or behavior of interest in the social sciences, but is less demanding than the assumptions required to generalize NSUM estimates to a target population.\n\n\n\n\nMy methodological expertise has also translated into substantive contributions in comparative politics and political behavior. I have primarily focused on issues of accountability, governance, and representation in the Global South. These contributions fall into two categories.\n\nFirst, I have focused on projects that help illuminate survey research practice. For example, in a manuscript conditionally accepted at the British Journal of Political Science with Virginia Oliveros (Tulane), Rebecca Weitz-Shapiro (Brown), and Matt Winters (Illinois), we use a survey experiment in Argentina to study gendered differential reactions to policy implementation. Previous work suggests that women face higher scrutiny for their performance in office. However, in the context of the implementation of a food distribution program, we find that voters are only responsive to performance information among men officeholders and tend to ignore performance information when told that an officeholder is a woman. We attribute this result to voters’ perception of men politicians as the default category, thus providing no new information on top of performance. In turn, mentioning the gender of a woman politician leads voters to believe that good performance stems from factors beyond the incumbent’s control. This has broader implications for research on gender gaps in the evaluation of public officials, since most survey-experimental analysis on the topic fail to account for this informational imbalance.\n\n\nA second set of projects focuses on applying methodological innovations to improve statistical precision in areas where researchers need it the most. For example, in a working paper with the same team that proposes combining list experiments with the NSUM, we document the prevalence of criminal governance strategies in Uruguay. This is a country with criminal organizations that are small in size but still deeply rooted in pockets of the capital city. Here, estimating the extent of exposure to criminal governance is challenging due to the combination of sensitivity bias and our inability to oversample on key subgroups of interest, which means any attempt to maximize statistical precision needs to come from our research design choices. This is the basis of an European Research Council grant application seeking to understand criminal governance in least-expected contexts from a comparative perspective, which will in turn serve as a platform for further methodological innovation in survey research."
  },
  {
    "objectID": "research.html#research-statement",
    "href": "research.html#research-statement",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\nPolitical scientists often study phenomena that cannot be observed directly. For example, we use responses to hypothetical survey questions to infer actual behavior, we resort to aggregate election results to understand individual evaluations of politicians’ performance in office, and we conduct randomized controlled trials in some places to determine if a policy is advisable in other places. Doing this credibly requires careful research design, since researchers must try to anticipate the challenges to inference even before conducting data analysis.\nMy research develops standards to navigate the tradeoffs that emerge when one considers research design options before data collection. I use tools from causal inference and computational social science to identify practices and procedures that researchers can adopt to improve how they approach data collection at the pre-analysis stage. My current agenda focuses on improving statistical precision, since this is often the deciding factor when choosing among alternative research designs, all promising unbiased estimators.\nI apply the insights of my methodological work to questions in comparative politics and political behavior, especially around the challenges to accountability, governance, and representation. The common theme across these applications is the goal of improving our ability to make statistical inferences about hard-to-observe social and political phenomena.\n\n\n\nThe last decade has seen considerable improvement in research transparency and registration. Recent advances in experimental design provide tools to diagnose the properties of a research design before data collection. For example, one can think about bias, power, or target sample size under different hypothetical data generation processes.\nA recurrent goal in statistics, econometrics, and political methodology is to minimize bias, or being close to the hypothetical truth on average. When planning an original data collection effort, researchers can often choose among many alternative research designs, all with previously identified unbiased estimators. My agenda focuses on optimizing statistical precision, understood as producing consistent results after multiple realizations of the same data generation process. While this is a crucial factor when choosing a research design, the literature implicitly assumes that one cam simply improve precision by increasing sample size, without providing much guidance to assess among alternative designs. Moreover, simply increasing sample size is not feasible in most applications due to practical or ethical considerations. Therefore, even when one does not face a choice between alternative designs, statistical precision is still paramount.\nFocusing on the design and analysis of experiments, my agenda advances the argument that the choice between alternative research designs for which unbiased estimators are already documented is rarely free. A design promising improvements in statistical precision without sacrificing unbiasedness often brings unforeseen costs in other dimensions.\nTwo projects exemplify how I develop standards to navigate research design choice under unforeseen challenges. First, In a manuscript with Erin Rossiter (Notre Dame), we discuss the circumstances under which adopting research design features aimed at improving precision can instead hurt it through implicit or explicit sample loss. For example, block randomization can improve precision, but if this requires contacting participants multiple times to collect pre-treatment blocking covariates, then it creates space for attrition that would not exist otherwise, which may offset the precision gains from blocking. We posit this is the main reason why researchers deviate from the standard experimental design infrequently. Through three replications and six reanalyses of previously published experiments in leading political science journals, we show how precision gains from alternative designs can withstand significant degrees of sample loss. From this exercise, we also identify guidelines to navigate the tradeoff between precision and sample retention in experiments.\nSecond, in a manuscript published at the Journal of Experimental Political Science, I propose statistical tests to address problems with double list experiments. Social scientists use list experiments in surveys when respondents may not answer truthfully to sensitive questions. When their assumptions are met, list experiments reduce sensitivity biases from misreporting. However, they tend to produce estimates with high variance, which prevents researchers from improving upon direct questioning. Double list experiments promise to remedy this by implementing two parallel list experiments and then aggregating their results, which roughly halves the variance of the estimate for the prevalence of the sensitive trait.\nThis implies an estimator that is more precise and still unbiased, but their implementation brings the question over whether the aggregation of the results of two parallel experiments yields a valid estimate. The tests leverage variation in the order in which respondents see the sensitive item to detect whether respondents are reacting to list experiment questions in unintended ways. This provides researchers with a tool to apply this underexplored variant of the technique more widely.\nThis agenda is currently extending toward improving precision by combining different techniques that target the same quantity of interest. For example, in work in progress with Inés Fynn (Universidad Católica del Uruguay), Verónica Pérez (Universidad de la República), and Lucía Tiscornia (University College Dublin), we combine list experiments and the network scale up method (NSUM), a popular technique in the health sciences, to improve precision in the estimation of the prevalence of sensitive attitudes and behaviors. Previous work combining different techniques to minimize sensitivity bias in survey questions relies on asking direct questions, altered research designs, cumbersome statistical modeling assumptions, or access to population-level data, all of which are problematic in their own way. By using NSUM questions as auxiliary information to the list experiment, we manage to improve precision by only imposing one additional assumption: that people with disproportionally high exposure to the sensitive trait of interest in their personal network are likely to hold the trait themselves. This does not apply to every sensitive attitude or behavior of interest in the social sciences, but is less demanding than the assumptions required to generalize NSUM estimates to a target population.\n\n\n\n\nMy methodological expertise has also translated into substantive contributions in comparative politics and political behavior. I have primarily focused on issues of accountability, governance, and representation in the Global South. These contributions fall into two categories.\n\nFirst, I have focused on projects that help illuminate survey research practice. For example, in a manuscript conditionally accepted at the British Journal of Political Science with Virginia Oliveros (Tulane), Rebecca Weitz-Shapiro (Brown), and Matt Winters (Illinois), we use a survey experiment in Argentina to study gendered differential reactions to policy implementation. Previous work suggests that women face higher scrutiny for their performance in office. However, in the context of the implementation of a food distribution program, we find that voters are only responsive to performance information among men officeholders and tend to ignore performance information when told that an officeholder is a woman. We attribute this result to voters’ perception of men politicians as the default category, thus providing no new information on top of performance. In turn, mentioning the gender of a woman politician leads voters to believe that good performance stems from factors beyond the incumbent’s control. This has broader implications for research on gender gaps in the evaluation of public officials, since most survey-experimental analysis on the topic fail to account for this informational imbalance.\n\n\nA second set of projects focuses on applying methodological innovations to improve statistical precision in areas where researchers need it the most. For example, in a working paper with the same team that proposes combining list experiments with the NSUM, we document the prevalence of criminal governance strategies in Uruguay. This is a country with criminal organizations that are small in size but still deeply rooted in pockets of the capital city. Here, estimating the extent of exposure to criminal governance is challenging due to the combination of sensitivity bias and our inability to oversample on key subgroups of interest, which means any attempt to maximize statistical precision needs to come from our research design choices. This is the basis of an European Research Council grant application seeking to understand criminal governance in least-expected contexts from a comparative perspective, which will in turn serve as a platform for further methodological innovation in survey research."
  },
  {
    "objectID": "cover.html",
    "href": "cover.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Dear Members of the Search Committee,\nI write to express my interest in your call for an Assistant Professor in Political Methodology. I am an Assistant Professor of Instruction in the Department of Political Science at Northwestern University, where I teach courses on statistics, statistical programming, and computational social science and conduct research on quantitative methods and social science research design. I received my PhD in Political Science from the University of Illinois Urbana-Champaign in 2021. My work is published or forthcoming in outlets including the British Journal of Political Science, World Development, and the Journal of Experimental Political Science.\n\n\n\nMy research agenda focuses on using statistics to improve research design before data collection. My current focus is on statistical precision. This is overlooked in the statistics, econometrics, and political methodology literature in favor of identifying unbiased estimators. Implicitly, this literature assumes that one can improve statistical precision by just increasing sample size. This is not feasible in many social science applications due to practical or ethical considerations.\nFocusing on the design and analysis of surveys and experiments, this agenda seeks to shape applied research by focusing on cases where one can seemingly improve statistical precision without sacrificing unbiasedness. As I show in my work, this usually implies unforeseen costs in other dimensions.\nFor example, in “Balancing Precision and Retention in Experimental Design”, we discuss how implementing alternatives to the standard experimental design, such as block randomization, may attenuate expected precision gains via explicit or implicit sample loss, a concern that prevents researchers from applying these techniques widely. Through three replications and six reanalyses of previously published experiments in leading political science journals, we show how precision gains from alternative designs can withstand significant degrees of sample loss.\nAs another example, in a solo-authored publication in the Journal of Experimental Political Science, I discuss the unforeseen costs of implementing double list experiments. This is a variant of the list experiment that promises narrower confidence intervals but comes with under-explored questionnaire design complications in the form of carryover design effects, a special kind of question order effect. I introduce parametric and nonparametric statistical tests to diagnose this effect, which in turn facilitate the implementation of a more statistically efficient technique.\n\nOne of the core lessons from my research program on statistical precision is that combining different techniques helps overcome their respective limitations. For example, in work in progress, we combine list experiments with questions from the network scale up method (NSUM), a popular technique in the health sciences, to improve the estimation of sensitive attitudes and behaviors. On the one hand, list experiments suffer from low statistical precision. On the other hand, generalizing to a population of interest through NSUM requires assumptions that are untenable in social science applications. By using NSUM questions as auxiliary information to the list experiment, we improve precision without introducing cumbersome assumptions.\n\nMy research also influences substantive work in comparative politics and political behavior. In a working paper, we follow on our efforts to incorporate NSUM into social science applications by documenting the prevalence of criminal governance strategies in Uruguay. This is the basis of an European Research Council grant application seeking to understand criminal governance in least-expected contexts from a comparative perspective, which will in turn serve as a platform for further methodological innovation.\nAs another example, in a manuscript conditionally accepted at the British Journal of Political Science, we use a survey experiment in Argentina to study gendered differential reactions to policy implementation. Previous work suggests that women face higher scrutiny for their performance in office. However, in the context of the implementation of a food distribution program, we find that voters are only responsive to performance information among men officeholders and tend to ignore performance information when told that an officeholder is a woman. We attribute this result to voters’ perception of men politicians as the default category, thus providing no new information on top of performance. In turn, mentioning the gender of a woman politician leads voters to believe that good performance stems from factors beyond the incumbent’s control. This has broader implications for research on gender gaps in the evaluation of public officials, since most survey-experimental analysis on the topic fail to account for this informational imbalance.\n\n\nMy teaching focuses on making quantitative methods accessible to diverse audiences through a combination of flexibility and accountability. At Northwestern, I am the central person teaching quantitative methods in the department. I teach the first course in the PhD methods sequence, focusing on probability and statistical inference. I also lead the math camp for incoming political science and sociology students and run the year-long R workshop that introduces cutting-edge statistical programming practices. Later this year, I will teach the undergrad-level introduction to empirical research in political science, and a seminar on causal inference and machine learning methods for evidence-informed decision-making.\nBefore joining Northwestern, I taught data analysis for public policy and public opinion at McMaster and evidence-based policy to address social and political challenges in developing democracies at Tulane. Both courses emphasized experimental and quasi-experimental designs to generate credible evidence. Beyond the classroom, my previous role as the methods editorial assistant for the American Political Science Review gave me the opportunity to shape and influence the development and application of cutting-edge methods in the field, a goal that I continue to pursue through service and mentoring.\n\n\n\n\n\nI am prepared to teach courses on statistics, research design, experiments, causal inference, machine learning, and computational social science. You can find copies of current and future syllabi in my website.\n\nI believe my expertise makes me an excellent fit at Wisconsin. If you have any questions, you can contact me via email or phone.\nSincerely,"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu"
  },
  {
    "objectID": "publications.html#publications",
    "href": "publications.html#publications",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu"
  },
  {
    "objectID": "publications.html#under-review-forthcoming",
    "href": "publications.html#under-review-forthcoming",
    "title": "Job Market Hub",
    "section": "Under review & Forthcoming",
    "text": "Under review & Forthcoming\n“Balancing Precision and Retention in Experimental Design” (with Erin Rossiter)\nUnder review at The American Journal of Political Science (submitted on August 2024)\n“Ignoring Female Performance: A Survey Experiment on Policy Implementation in Argentina.” (with Virginia Oliveros, Rebecca Weitz-Shapiro, and Matthew S. Winters)\nConditionally accepted at The British Journal of Political Science"
  },
  {
    "objectID": "publications.html#published",
    "href": "publications.html#published",
    "title": "Job Market Hub",
    "section": "Published",
    "text": "Published\n2024. “Assessing the Validity of Prevalence Estimates in Double List Experiments.” Journal of Experimental Political Science 11(2): 162-174\n2024. “Data Sources for the Study of Gender and Corruption.” In Handbook on Gender and Corruption in Democracies, edited by Emily Beaulieu Bacchus and Tiffany Barnes. Edward Elgar Publishing (with Kelly Senters Piazza)\n2022. “Women Held Back: The Depressing Effect of Institutional and Norms-Based Barriers on Female Representation in Corrupt Contexts.” In Norms, Gender and Corruption: Understanding the Nexus, edited by Ina Kubbe and Ortrun Merkle. Edward Elgar Publishing (with Kelly Senters Piazza)\n2020. “Light in the Midst of Chaos: COVID-19 and Female Political Representation.” World Development 136: 105125 (with Kelly Senters Piazza)\n2020. “Survey Experiments and the Quest for Valid Interpretation.” In The SAGE Handbook of Research Methods in Political Science and International Relations, edited by Luigi Curini and Robert Franzese. London: Sage (with Christopher Grady and James H. Kuklinski)\n2014. “Civic Education and Voter Turnout Under Voluntary Voting.” Política 52(1): 61-91 (In Spanish)"
  },
  {
    "objectID": "diversity.html",
    "href": "diversity.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\nI am a first-generation scholar in three ways. I am part of the first generation in my family to receive a bachelor’s degree, part of the first generation seeking postgraduate education opportunities overseas, and the only person in my family pursuing an academic career. The other “part” is an older sibling that tried to convince me to follow their steps and become and economics major. I refused, since I thought it would involve too much math. I chose political science instead, as it seemed to have less math but still enough to meet family expectations. I was wrong. It had as much math, and I hated until I learned halfway through that I could use data to generate knowledge.\nMy personal experience puts me in a privileged position to foster diversity and inclusion in statistics and social science methodology. While the job of the methodologist is to act as a conduit between theoretical and applied work, I recognize that the traditional higher education setting does not allow individuals from underrepresented backgrounds to participate in that information exchange on equal footing. I believe this is not due to inequality in previous training, but rather because the conventional spaces for cutting-edge knowledge generation and communication are not sufficiently welcoming for individuals that do not fit into conventional disciplinary molds.\nMy initial efforts focused on facilitating out-of-classroom learning opportunities, which I consider essential to break initial entry barriers. At Illinois, I started a methods cheatsheets project in 2018. In this project, volunteer graduate students write short introductions to the theory, implementation, and current debates surrounding a technique of their expertise. These resources are shared in a repository available for current and future generations.\nAt Northwestern, I facilitate collaborative lab-style spaces for open-ended group work. As part of both my introductory graduate methods course and the R workshop I organize, participants can bring their own methods-related work to the lab session and benefit from group learning in a low-stakes setting.\nI also incorporate these principles into my teaching. My course on data analysis for public opinion and policy at McMaster gave students enough flexibility to connect statistical theory to their own interests and career goals. For example, in response papers they could choose what parts of a research design they would change if they were in charge of replicating a study on a topic of their choosing.\nIn the future, I aim to form a research group that translates these ideas into a sustainable and inclusive research program. This group would foster dialogue across backgrounds, learning styles, and career stages, while also providing a safety net to provide early support to those who may otherwise struggle."
  },
  {
    "objectID": "diversity.html#diversity-statement",
    "href": "diversity.html#diversity-statement",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu\nI am a first-generation scholar in three ways. I am part of the first generation in my family to receive a bachelor’s degree, part of the first generation seeking postgraduate education opportunities overseas, and the only person in my family pursuing an academic career. The other “part” is an older sibling that tried to convince me to follow their steps and become and economics major. I refused, since I thought it would involve too much math. I chose political science instead, as it seemed to have less math but still enough to meet family expectations. I was wrong. It had as much math, and I hated until I learned halfway through that I could use data to generate knowledge.\nMy personal experience puts me in a privileged position to foster diversity and inclusion in statistics and social science methodology. While the job of the methodologist is to act as a conduit between theoretical and applied work, I recognize that the traditional higher education setting does not allow individuals from underrepresented backgrounds to participate in that information exchange on equal footing. I believe this is not due to inequality in previous training, but rather because the conventional spaces for cutting-edge knowledge generation and communication are not sufficiently welcoming for individuals that do not fit into conventional disciplinary molds.\nMy initial efforts focused on facilitating out-of-classroom learning opportunities, which I consider essential to break initial entry barriers. At Illinois, I started a methods cheatsheets project in 2018. In this project, volunteer graduate students write short introductions to the theory, implementation, and current debates surrounding a technique of their expertise. These resources are shared in a repository available for current and future generations.\nAt Northwestern, I facilitate collaborative lab-style spaces for open-ended group work. As part of both my introductory graduate methods course and the R workshop I organize, participants can bring their own methods-related work to the lab session and benefit from group learning in a low-stakes setting.\nI also incorporate these principles into my teaching. My course on data analysis for public opinion and policy at McMaster gave students enough flexibility to connect statistical theory to their own interests and career goals. For example, in response papers they could choose what parts of a research design they would change if they were in charge of replicating a study on a topic of their choosing.\nIn the future, I aim to form a research group that translates these ideas into a sustainable and inclusive research program. This group would foster dialogue across backgrounds, learning styles, and career stages, while also providing a safety net to provide early support to those who may otherwise struggle."
  },
  {
    "objectID": "cover_teaching.html",
    "href": "cover_teaching.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Dear Members of the Search Committee,\nI write to express my interest in your call for a Clinical Assistant Professor in Applied Statistics for Social Science Research. I am an Assistant Professor of Instruction in the Department of Political Science at Northwestern University, where I teach courses on statistics, statistical computing, and computational social science. I received my PhD from the University of Illinois Urbana-Champaign in 2021.\n\n\nMy teaching focuses on making statistics accessible to diverse audiences through a combination of flexibility and accountability. At Northwestern, I am the central person teaching statistics courses in the department. I teach the first course in the PhD methods sequence, focusing on probability and statistical inference, and an undergrad-level introductory course that helps political science majors become informed consumers of applied statistics. I also lead the math camp for incoming political science and sociology students and run the year-long statistical computing workshop that introduces cutting-edge coding practices. Later this year, I will teach a seminar on the use of design-based causal inference and machine learning methods to inform decision-making in academia, government, and industry. Next year, my goal is to teach an advanced graduate practicum on machine learning methods for statistical inference.\nBefore joining Northwestern, I taught data analysis for public policy and public opinion at McMaster and evidence-based policy to address social and political challenges in developing democracies at Tulane. Both courses emphasized the use of applied statistics to generate credible evidence. Beyond the classroom, my previous role as the methods editorial assistant for the American Political Science Review gave me the opportunity to shape and influence the development of cutting-edge methods in the field, a goal that I continue to pursue through service and mentoring.\n\n\n\n\n\nI am prepared to teach courses on probability and statistical inference, statistical computing, causal inference, machine learning, and computational social science. You can find copies of current and future syllabi in my website.\n\n\n\nMy research agenda focuses on using statistics to improve research design before data collection. My current focus is on statistical precision. This is overlooked in the statistics, econometrics, and political methodology literature in favor of identifying unbiased estimators. Implicitly, this literature assumes that one can improve statistical precision by just increasing sample size. This is not feasible in many social science applications due to practical or ethical considerations.\nFocusing on the design and analysis of surveys and experiments, this agenda seeks to shape applied research by focusing on cases where one can seemingly improve statistical precision without sacrificing unbiasedness. As I show in my work, this usually implies unforeseen costs in other dimensions.\nFor example, in “Balancing Precision and Retention in Experimental Design”, we discuss how implementing alternatives to the standard experimental design, such as block randomization, may attenuate expected precision gains via explicit or implicit sample loss, a concern that prevents researchers from applying these techniques widely. Through three replications and six reanalyses of previously published experiments in leading political science journals, we show how precision gains from alternative designs can withstand significant degrees of sample loss.\n\nAs another example, in a solo-authored publication in the Journal of Experimental Political Science, I discuss the unforeseen costs of implementing double list experiments. This is a variant of the list experiment that promises narrower confidence intervals but comes with under-explored questionnaire design complications in the form of carryover design effects, a special kind of question order effect. I introduce statistical tests to diagnose this effect, which in turn facilitate the implementation of a more efficient technique.\n\nOne of the core lessons from my research program on statistical precision is that combining different techniques helps overcome their respective limitations. For example, in work in progress, we combine list experiments with questions from the network scale up method (NSUM), a popular technique in the health sciences, to improve the estimation of sensitive attitudes and behaviors. On the one hand, list experiments suffer from low statistical precision. On the other hand, generalizing to a population of interest through NSUM requires assumptions that are untenable in social science applications. By using NSUM questions as auxiliary information to the list experiment, we improve precision without introducing cumbersome assumptions.\n\nMy research also influences substantive work in the social sciences. In a working paper, we follow on our efforts to incorporate NSUM into social science applications by documenting the prevalence of criminal governance strategies in Uruguay. This is the basis of an European Research Council grant application seeking to understand criminal governance in least-expected contexts from a comparative perspective, which will in turn serve as a platform for further methodological innovation.\nAs another example, in a manuscript forthcoming at the British Journal of Political Science, we use an information experiment in Argentina to study gendered differential reactions to policy implementation. Previous work suggests that women face higher scrutiny for their performance in office. However, in the context of the implementation of a food distribution program, we find that voters are only responsive to performance information among men officeholders and tend to ignore performance information when told that an officeholder is a woman. We attribute this result to voters’ perception of men politicians as the default category, and the tendency to believe that women politicians’ good performance stems from factors beyond the incumbent’s control. This finding calls attention to an unforeseen informational imbalance on survey experimental work in the subject, which future studies should take into account.\n\nI believe my expertise makes me an excellent fit at NYU. If you have any questions, you can contact me via email or phone.\nSincerely,"
  },
  {
    "objectID": "personal.html",
    "href": "personal.html",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu"
  },
  {
    "objectID": "personal.html#personal-statement",
    "href": "personal.html#personal-statement",
    "title": "Job Market Hub",
    "section": "",
    "text": "Gustavo Diaz\nDepartment of Political Science\nNorthwestern University\ngustavo.diaz@northwestern.edu"
  },
  {
    "objectID": "personal.html#research-agenda",
    "href": "personal.html#research-agenda",
    "title": "Job Market Hub",
    "section": "Research agenda",
    "text": "Research agenda\nPolitical scientists often study phenomena that cannot be observed directly. For example, we use responses to hypothetical survey questions to infer actual behavior, we resort to aggregate election results to understand individual evaluations of politicians’ performance in office, and we conduct randomized controlled trials in some places to determine if a policy is advisable in other places. Doing this credibly requires careful research design, since researchers must try to anticipate the challenges to inference even before conducting data analysis.\nMy research develops standards to navigate the tradeoffs that emerge when as considers research design alternatives before data collection. I use tools from statistics and computational social science to identify practices and procedures that researchers can adopt to improve how they approach data collection at the pre-analysis stage. My current agenda focuses on improving statistical precision, since this is often the deciding factor when choosing among alternative research designs, all promising unbiased estimators.\nI apply the insights of my methodological work to questions around the challenges to accountability and representation in political economy and political behavior. The common theme across these applications is the goal of improving our ability to make statistical inferences about hard-to-observe social and political phenomena, which in turn leads to a more credible evidence base to support decision-making. For the sake of brevity, this document focuses on my methodological agenda only.\nThe last decade has seen considerable improvement in research transparency and registration. Recent advances in experimental design provide tools to diagnose the properties of a research design before data collection. For example, one can think about bias, power, or target sample size under different hypothetical data generation processes.\nA recurrent goal in statistics, econometrics, and social science methodology is to minimize bias, or being close to the hypothetical truth on average. When planning an original data collection effort, researchers can often choose among many alternative research designs, all with previously identified unbiased estimators. My agenda focuses on optimizing statistical precision, understood as producing consistent results after multiple realizations of the same data generation process. While this is a crucial factor when choosing a research design, the literature implicitly assumes that one can simply improve precision by increasing sample size, without providing much guidance to assess among alternative designs. Moreover, simply increasing sample size is not feasible in most applications due to practical or ethical considerations. Therefore, even when one does not face a choice between alternative designs, statistical precision is still paramount.\nFocusing on the design and analysis of surveys and experiments, my agenda advances the argument that the choice between alternative research designs for which unbiased estimators are already documented is rarely free. A design promising improvements in statistical precision without sacrificing unbiasedness often brings unforeseen costs in other dimensions.\nTwo projects exemplify how I develop standards to navigate research design choices under unforeseen challenges. First, in a manuscript conditionally accepted at Political Analysis with Erin Rossiter (Notre Dame), we discuss the circumstances under which adopting research design features aimed at improving precision can instead hurt it through implicit or explicit sample loss. For example, block randomization can improve precision, but if this requires contacting participants multiple times to collect pre-treatment blocking covariates, then it creates space for attrition that would not exist otherwise, which may offset the precision gains from blocking. We posit this is the main reason why researchers deviate from the standard experimental design infrequently. Through three replications and six reanalyses of previously published experiments in leading political science journals, we show how precision gains from alternative designs can withstand significant degrees of sample loss. From this exercise, we also identify guidelines to navigate the tradeoff between precision and sample retention in experiments.\nSecond, in a manuscript published at the Journal of Experimental Political Science, I propose statistical tests to address problems with double list experiments. Social scientists use list experiments in surveys when respondents may not answer truthfully to sensitive questions. When their assumptions are met, list experiments reduce sensitivity biases from misreporting. However, they tend to produce estimates with high variance, which prevents researchers from improving upon direct questioning. Double list experiments promise to remedy this by implementing two parallel list experiments and then aggregating their results, which roughly halves the variance of the estimate for the prevalence of the sensitive trait.\nThis implies an estimator that is more precise and still unbiased, but their implementation brings the question over whether the aggregation of the results of two parallel experiments yields a valid estimate. The tests leverage variation in the order in which respondents see the sensitive item to detect whether respondents are reacting to list experiment questions in unintended ways. This provides researchers with a tool to apply this underexplored variant of the technique more widely.\nThis agenda is currently extending toward improving precision by combining different techniques that target the same quantity of interest. For example, in work in progress with Inés Fynn (Universidad Católica del Uruguay), Verónica Pérez (Universidad de la República), and Lucía Tiscornia (University College Dublin), we combine list experiments and the network scale up method (NSUM), a popular technique in the health sciences, to improve precision in the estimation of the prevalence of sensitive attitudes and behaviors. Previous work combining different techniques to minimize sensitivity bias in survey questions relies on asking direct questions, altered research designs, cumbersome statistical modeling assumptions, or access to population-level data, all of which are problematic in their own way. By using NSUM questions as auxiliary information to the list experiment, we manage to improve precision by only imposing one additional assumption: that people with disproportionally high exposure to the sensitive trait of interest in their personal network are likely to hold the trait themselves. This does not apply to every sensitive attitude or behavior of interest in the social sciences, but is less demanding than the assumptions required to generalize NSUM estimates to a target population."
  },
  {
    "objectID": "personal.html#teaching-philosophy-and-experience",
    "href": "personal.html#teaching-philosophy-and-experience",
    "title": "Job Market Hub",
    "section": "Teaching philosophy and experience",
    "text": "Teaching philosophy and experience\nAs an instructor of quantitative methods for political scientists, I face a polarized audience. Increasingly, students start their program with considerable experience in mathematical thinking, statistics, and statistical programming. Still, many start with an appreciation for data analysis, but come from educational and career paths designed to explicitly avoid math.\nMy approach to keep both audiences engaged within one term is to unify math, statistics, and coding as the task of acquiring a new language. A single course will not teach students everything they need to know to become fluent, but it can give enough tools to facilitate future learning in a direction that is beneficial to students regardless of their background and career goals. For some, this may mean engaging directly with data and code or even creating new methodologies. For others, the goal may be just to communicate productively with scholarship drawing on quantitative findings or data analysts at the workplace.\nTo accommodate this diversity, I design courses with two principles in mind. First, students need flexibility to engage with the course on their own terms and focus on the content they find useful. For example, the flipped classroom lab sessions in my course on data analysis for public opinion and policy at McMaster asked students to evaluate a research design, suggest alternatives or modifications, and to evaluate its statistical properties through coding and writing. Some students may propose increasing the sample size, sampling from a different underlying population, or changing the assignment of treatment conditions. This allows students to pursue the tasks that suit their interests and gives the instructor freedom to reward creativity and effort over correctness.\nThe flexibility principle also applies to the problem sets in my graduate introductory methods course, where contract grading allows me to reward learning even when students get stuck with coding. I place equal value on reasoning why something did not work and how it should look had the code worked properly as I do on producing working code. This reduces anxiety around finding the right answers, and encourages creativity and collaboration.\nThe second principle is accountability, which is necessary to keep everyone on task while allowing flexibility. This means agreeing on an overarching theme that every single course activity must relate to. For example, early on my data analysis for public opinion and policy course, I introduce the bias-variance tradeoff as a principle to choose among alternative research designs. So, while students are free to propose any modification to an existing research design that they deem appropriate, they are also required to identify the explicit or implicit costs associated with their proposal. They must consider, for instance, that a representative sample is more expensive than a convenience sample, or that implementing a block-randomized experiment may require access to variables that cannot be measured easily.\nSimilarly, the overarching theme in my graduate probability and statistics course is how assumptions shape the inferences that we can credibly draw from data. I emphasize how we need to make unrealistic assumptions, even if minimal, to enable statistical inference, and that we need to hold ourselves accountable to those assumptions when evaluating the appropriateness of a statistical procedure.\nFlexibility and accountability also help in preventing instances of discrimination in the learning process. Through flexibility, students are invited to add value to the course by bringing their own perspective, knowledge, or experiences. In turn, accountability sets the scope for the type of contributions of interventions that are admissible. From this perspective, a racist remark is unacceptable not because someone disagrees with it, but because it is beyond the scope of the vocabulary we aim to build.\nIn terms of experience, I am the central person teaching statistics courses at Northwestern political science. I teach the first course in the graduate methods sequence, focusing on probability and statistical inference. At the undergraduate level, I also teach the introduction to research methods in political science, a course that teaches political science majors to become informed consumers of data analysis and prepares them for more advanced courses, and a research seminar on the use of experiments and machine learning to inform decision-making in academia, policy, and industry. I also lead the math camp program for incoming political science and sociology students, and run the year-long statistical computing workshop that introduces cutting-edge coding practices. Next year, I will add a graduate seminar on machine learning to my portfolio.\nBefore joining Northwestern, I taught data analysis for public policy and public opinion at McMaster, with emphasis on using quantitative evidence to make credible policy recommendations. The goal of this course is to give students hands-on experience in designing quantitative research projects in an area relevant to academia, policy, or industry.\nAt Tulane, I taught an undergrad senior course on the challenges that developing democracies face from the perspective of evidence-based policy making. This course overviews the main challenges in the path to democratic consolidation around the world, proposed solutions to these challenges, and how governments, researchers, and civil society organizations use data to evaluate these solutions. The previous version focused primarily design-based causal inference, but future versions will also feature data science and machine learning.\nI am prepared to teach both departmental and service courses on research design, quantitative methods, statistical computing, machine learning, causal inference, and experiments. You can find copies of current and future syllabi in my website."
  },
  {
    "objectID": "personal.html#service",
    "href": "personal.html#service",
    "title": "Job Market Hub",
    "section": "Service",
    "text": "Service\nI have devoted most of my service experience into making cutting-edge training and experience in quantitative methods as accessible as possible. Before joining Northwestern, I served as the research methods editorial assistant at the American Political Science Review. My primary mission in this role was to expand the reviewer pool to incorporate a higher proportion of early career scholars in the evaluation of highly technical submissions.\nMy long-term goal is to create or expand existing opportunities to incorporate students and early career scholars into a sustainable research pipeline centered on cutting-edge applications of statistical methods. My initial efforts in this matter have focused on working closely with undergraduate students. For example, as a graduate student at Illinois, I worked closely with an undergraduate research assistant to learn about topic modeling for text analysis together, which helped both my dissertations and the student’s future career in data analysis for industry. Currently, I mentor a rising sophomore at Northwestern to incorporate them as co-authors on projects on experimental research design. With access to a bigger platform, I foresee growing toward a lab group that continuously trains and mentors students and recent graduates across all levels."
  }
]